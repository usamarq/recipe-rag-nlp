{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3683f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # Added numpy for percentile calculation\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Setup\n",
    "# ---------------------------------------------\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "# Assuming 'df' is your DataFrame loaded and columns cleaned\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Define columns to explore\n",
    "# ---------------------------------------------\n",
    "nutritional_cols = [\n",
    "    'calories_cal',\n",
    "    'protein_g',\n",
    "    'totalfat_g',\n",
    "    'saturatedfat_g',\n",
    "    'cholesterol_mg',\n",
    "    'sodium_mg',\n",
    "    'totalcarbohydrate_g',\n",
    "    'dietaryfiber_g',\n",
    "    'sugars_g',\n",
    "    'duration',\n",
    "    'ingredients_sizes',\n",
    "    'who_score',\n",
    "    'fsa_score',\n",
    "    'nutri_score'\n",
    "\n",
    "]\n",
    "\n",
    "# Nicely formatted titles for plots\n",
    "titles = {\n",
    "    'calories_cal': 'Calories Distribution (99th Percentile)',\n",
    "    'protein_g': 'Protein Distribution (99th Percentile)',\n",
    "    'totalfat_g': 'Total Fat Distribution (99th Percentile)',\n",
    "    'saturatedfat_g': 'Saturated Fat Distribution (99th Percentile)',\n",
    "    'cholesterol_mg': 'Cholesterol Distribution (99th Percentile)',\n",
    "    'sodium_mg': 'Sodium Distribution (99th Percentile)',\n",
    "    'totalcarbohydrate_g': 'Total Carbohydrates Distribution (99th Percentile)',\n",
    "    'dietaryfiber_g': 'Dietary Fiber Distribution (99th Percentile)',\n",
    "    'sugars_g': 'Sugar Distribution (99th Percentile)',\n",
    "    'duration': 'Cooking Duration Distribution (99th Percentile)',\n",
    "    'ingredients_sizes': 'Ingredient Sizes Distribution (99th Percentile)',\n",
    "    'who_score': 'WHO Score Distribution', # Scores usually don't need filtering, but kept consistent for structure\n",
    "    'fsa_score': 'FSA Score Distribution',\n",
    "    'nutri_score': 'Nutritional Score Distribution'\n",
    "}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Plot all nutritional distributions in a grid (with percentile filtering)\n",
    "# ---------------------------------------------\n",
    "n = len(nutritional_cols)\n",
    "rows = (n + 2) // 3  # roughly 3 per row\n",
    "\n",
    "fig, axes = plt.subplots(rows, 3, figsize=(18, 5 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(nutritional_cols):\n",
    "    if col in df.columns:\n",
    "        # --- Filtering Added Here ---\n",
    "        data_to_plot = df[col].dropna() # Drop NaNs for calculation and plotting\n",
    "        if pd.api.types.is_numeric_dtype(data_to_plot) and not data_to_plot.empty:\n",
    "            q99 = np.percentile(data_to_plot, 99)\n",
    "            # Apply filtering mainly to columns prone to extreme outliers\n",
    "            # Scores might not need it, but apply consistently unless specified otherwise\n",
    "            if q99 > 0: # Avoid filtering if q99 is 0 or negative\n",
    "               filtered_data = data_to_plot[data_to_plot <= q99]\n",
    "            else:\n",
    "               filtered_data = data_to_plot # Don't filter if percentile is non-positive\n",
    "        else:\n",
    "            filtered_data = data_to_plot # Use original data if not numeric or empty after dropna\n",
    "\n",
    "        # Check if filtered_data is empty before plotting\n",
    "        if not filtered_data.empty:\n",
    "             sns.histplot(filtered_data, bins=50, ax=axes[i], color='mediumseagreen', edgecolor='black', kde=True)\n",
    "             axes[i].set_title(titles[col], fontsize=14)\n",
    "             axes[i].set_xlabel(col.replace('_', ' ').title())\n",
    "             # Optionally set xlim to focus the view, especially for filtered columns\n",
    "             if col not in ['who_score', 'fsa_score', 'nutri_score'] and q99 > 0: # Check q99 > 0\n",
    "                  axes[i].set_xlim(0, q99)\n",
    "             axes[i].set_ylabel('Frequency') # Add y-label\n",
    "        else:\n",
    "             axes[i].set_title(f\"{titles[col]}\\n(No data after filtering)\", fontsize=14)\n",
    "             axes[i].set_xlabel(col.replace('_', ' ').title())\n",
    "             axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    else:\n",
    "        axes[i].set_visible(False) # Hide axis if column not found\n",
    "\n",
    "# Hide any empty subplots if the number of columns < grid size\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "fig.suptitle('Nutritional Attribute Distributions (Filtered to 99th Percentile)', fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# bm25_search.py (initial unoptimized version)\n",
    "# Task 3 â€“ Simple BM25-based retrieval for recipe search\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from text_preprocessing import preprocess_text\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Load the preprocessed dataset\n",
    "# -------------------------------------------------\n",
    "def load_dataset(path=\"data/hummus_recipes_preprocessed.csv\"):\n",
    "    print(f\"ðŸ“‚ Loading dataset from: {path}\")\n",
    "    df = pd.read_csv(path, low_memory=True)\n",
    "    print(f\"âœ… Dataset shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Build or load BM25 index\n",
    "# -------------------------------------------------\n",
    "def build_bm25_index(df, index_path=\"data/bm25_index.pkl\", tokens_path=\"data/tokenized_docs.pkl\"):\n",
    "    \"\"\"\n",
    "    Builds or loads a cached BM25 index and tokenized documents.\n",
    "    \"\"\"\n",
    "    if os.path.exists(index_path) and os.path.exists(tokens_path):\n",
    "        print(f\"ðŸ“¦ Loading cached BM25 index from disk...\")\n",
    "        with open(index_path, \"rb\") as f:\n",
    "            bm25 = pickle.load(f)\n",
    "        tokenized_docs = joblib.load(tokens_path)\n",
    "        print(f\"âœ… Loaded BM25 index for {len(tokenized_docs)} recipes.\")\n",
    "        return bm25, tokenized_docs\n",
    "\n",
    "    print(\"âš™ï¸ Building new BM25 index...\")\n",
    "\n",
    "    # Combine relevant processed text columns\n",
    "    text_cols = [\"processed_title\", \"processed_ingredients\", \"processed_tags\", \"processed_directions\"]\n",
    "    available_cols = [c for c in text_cols if c in df.columns]\n",
    "    print(f\"Using columns: {available_cols}\")\n",
    "\n",
    "    # Combine text into one document per recipe\n",
    "    df[\"combined_text\"] = df[available_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "    # Tokenize (already preprocessed)\n",
    "    tokenized_docs = [doc.split() for doc in df[\"combined_text\"]]\n",
    "\n",
    "    # Build BM25\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "\n",
    "    # Save both index and tokenized docs for reuse\n",
    "    with open(index_path, \"wb\") as f:\n",
    "        pickle.dump(bm25, f)\n",
    "    joblib.dump(tokenized_docs, tokens_path)\n",
    "\n",
    "    print(f\"âœ… BM25 index built and saved for {len(tokenized_docs)} recipes.\")\n",
    "    return bm25, tokenized_docs\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Preprocess and search\n",
    "# -------------------------------------------------\n",
    "def preprocess_query(query: str):\n",
    "    \"\"\"Apply the same preprocessing as dataset text.\"\"\"\n",
    "    return preprocess_text(query)\n",
    "\n",
    "\n",
    "def search_bm25(query: str, bm25, df, top_k=5):\n",
    "    \"\"\"Search using BM25 and return top_k results.\"\"\"\n",
    "    print(f\"\\nðŸ” Query: {query}\")\n",
    "    tokens = preprocess_query(query)\n",
    "    if not tokens:\n",
    "        print(\"âš ï¸ Query resulted in no valid tokens after preprocessing.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    scores = bm25.get_scores(tokens)\n",
    "    top_indices = scores.argsort()[-top_k:][::-1]\n",
    "\n",
    "    print(f\"\\nTop {top_k} results:\")\n",
    "    for rank, idx in enumerate(top_indices, 1):\n",
    "        title = df.loc[idx, \"title\"] if \"title\" in df.columns else \"(no title)\"\n",
    "        cal = df.loc[idx, \"calories_cal\"] if \"calories_cal\" in df.columns else \"?\"\n",
    "        print(f\"{rank}. {title}  ({cal} cal)\")\n",
    "\n",
    "    return df.iloc[top_indices][[\"title\", \"calories_cal\", \"totalfat_g\", \"protein_g\"]]\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Run example\n",
    "# -------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_dataset()\n",
    "    bm25, _ = build_bm25_index(df)\n",
    "\n",
    "    # Example queries\n",
    "    search_bm25(\"low fat chicken under 500 calories\", bm25, df, top_k=5)\n",
    "    search_bm25(\"high protein vegan salad\", bm25, df, top_k=5)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
